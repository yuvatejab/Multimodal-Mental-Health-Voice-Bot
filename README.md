# Mental Health Voice Bot ğŸ™ï¸ğŸ’™

A compassionate, voice-first mental health support chatbot with multilingual support. Built with FastAPI, React, and powered by Groq's ultra-fast AI models.

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Python](https://img.shields.io/badge/python-3.11+-blue.svg)
![React](https://img.shields.io/badge/react-18.2+-blue.svg)

## âœ¨ Features

- ğŸ¤ **Voice-First Experience**: Natural voice conversations with real-time processing
- ğŸŒ **Multilingual Support**: 10+ languages including English, Hindi, Spanish, French, German, Portuguese, Italian, Japanese, Korean, and Chinese
- âš¡ **Ultra-Fast Inference**: Powered by Groq's LPU for near-instant responses (<2 seconds end-to-end)
- ğŸ”’ **Privacy-Focused**: Conversations are ephemeral with no persistent storage
- ğŸ¨ **Modern UI**: Beautiful, calming interface with smooth animations
- ğŸš¨ **Crisis Detection**: Identifies crisis indicators and provides appropriate resources
- ğŸ†“ **100% Free**: Uses free APIs (Groq, Edge TTS) with generous limits

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   React Frontend â”‚
â”‚   (Vite + Tailwind) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ REST API
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FastAPI Backend â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ STT Serviceâ”‚ â”‚  â† Groq Whisper
â”‚  â”‚ LLM Serviceâ”‚ â”‚  â† Groq Llama 3.1
â”‚  â”‚ TTS Serviceâ”‚ â”‚  â† Edge TTS
â”‚  â”‚ Therapy Svcâ”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+
- Node.js 18+
- Groq API key (free from [console.groq.com](https://console.groq.com))

### 1. Clone the Repository

```bash
git clone <your-repo-url>
cd mental-health-voice-bot
```

### 2. Backend Setup

```bash
# Navigate to backend directory
cd backend

# Create virtual environment
python -m venv venv

# Activate virtual environment
# On Windows:
venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Create .env file
cp ../.env.example .env

# Edit .env and add your Groq API key
# GROQ_API_KEY=your_actual_api_key_here
```

### 3. Frontend Setup

```bash
# Navigate to frontend directory (from project root)
cd frontend

# Install dependencies
npm install

# Create .env file
cp .env.example .env

# The default settings should work for local development
```

### 4. Run the Application

**Terminal 1 - Backend:**
```bash
cd backend
# Make sure virtual environment is activated
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

**Terminal 2 - Frontend:**
```bash
cd frontend
npm run dev
```

**Access the application:**
- Frontend: http://localhost:5173
- Backend API: http://localhost:8000
- API Documentation: http://localhost:8000/docs

## ğŸ“ Project Structure

```
mental-health-voice-bot/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py              # FastAPI application entry
â”‚   â”‚   â”œâ”€â”€ config.py            # Configuration and settings
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â””â”€â”€ schemas.py       # Pydantic models
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ stt_service.py   # Speech-to-text (Groq Whisper)
â”‚   â”‚   â”‚   â”œâ”€â”€ llm_service.py   # LLM responses (Groq Llama)
â”‚   â”‚   â”‚   â”œâ”€â”€ tts_service.py   # Text-to-speech (Edge TTS)
â”‚   â”‚   â”‚   â””â”€â”€ therapy_service.py # Mental health logic
â”‚   â”‚   â””â”€â”€ routes/
â”‚   â”‚       â””â”€â”€ chat_routes.py   # API endpoints
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ VoiceRecorder.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatInterface.jsx
â”‚   â”‚   â”‚   â””â”€â”€ LanguageSelector.jsx
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ api.js           # API client
â”‚   â”‚   â”œâ”€â”€ App.jsx
â”‚   â”‚   â”œâ”€â”€ main.jsx
â”‚   â”‚   â””â”€â”€ index.css
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.js
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ render.yaml                   # Render.com deployment config
â””â”€â”€ README.md
```

## ğŸŒ API Endpoints

### Health Check
```
GET /api/health
```

### Get Supported Languages
```
GET /api/languages
```

### Voice Chat (Complete Pipeline)
```
POST /api/voice-chat
Content-Type: multipart/form-data

Parameters:
- audio: Audio file (webm, mp3, wav)
- language: Language code (optional)
- session_id: Session identifier (optional)
```

### Text Chat
```
POST /api/chat
Content-Type: application/json

Body:
{
  "message": "I'm feeling anxious today",
  "language": "en",
  "conversation_history": []
}
```

### Transcribe Audio
```
POST /api/transcribe
Content-Type: multipart/form-data

Parameters:
- audio: Audio file
- language: Language code
```

## ğŸš¢ Deployment

### Deploy to Render.com (Recommended - Free Tier)

1. **Push your code to GitHub**

2. **Sign up at [Render.com](https://render.com)**

3. **Create a new Blueprint**
   - Connect your GitHub repository
   - Render will automatically detect the `render.yaml` file

4. **Add Environment Variables**
   - In the backend service settings, add:
     - `GROQ_API_KEY`: Your Groq API key

5. **Deploy**
   - Render will automatically build and deploy both services
   - Frontend URL: `https://mental-health-voice-bot-frontend.onrender.com`
   - Backend URL: `https://mental-health-voice-bot-backend.onrender.com`

### Alternative: Deploy to Vercel (Frontend) + Render (Backend)

**Backend on Render:**
```bash
# Same as above for backend
```

**Frontend on Vercel:**
```bash
cd frontend
npm install -g vercel
vercel

# Set environment variable:
# VITE_API_URL=https://your-backend-url.onrender.com
```

## ğŸ”‘ Getting API Keys

### Groq API Key (Required)
1. Visit [console.groq.com](https://console.groq.com)
2. Sign up for a free account
3. Navigate to API Keys section
4. Create a new API key
5. Copy and add to your `.env` file

**Free Tier Limits:**
- 14,400 requests per day
- 500+ tokens/second
- More than enough for personal projects and portfolios

## ğŸ¨ Customization

### Adding New Languages

Edit `backend/app/config.py`:
```python
SUPPORTED_LANGUAGES: dict = {
    "your_lang_code": {
        "name": "Language Name",
        "voice": "edge-tts-voice-code"
    }
}
```

Find Edge TTS voices: [Edge TTS Voice List](https://github.com/rany2/edge-tts#voice-list)

### Customizing the System Prompt

Edit `backend/app/services/llm_service.py` - modify the `system_prompt` variable.

### Changing UI Colors

Edit `frontend/tailwind.config.js` to customize the color scheme.

## ğŸ§ª Testing

### Manual Testing Checklist

- [ ] Record voice message in English
- [ ] Test different languages (Hindi, Spanish, etc.)
- [ ] Verify audio playback works
- [ ] Test crisis keyword detection
- [ ] Check mobile responsiveness
- [ ] Verify conversation history
- [ ] Test clear conversation feature

### Testing Crisis Detection

Try phrases like:
- "I'm feeling suicidal"
- "I want to hurt myself"

The bot should respond with crisis resources.

## ğŸ› ï¸ Troubleshooting

### Backend Issues

**"GROQ_API_KEY is not set"**
- Make sure you created a `.env` file in the backend directory
- Verify the API key is correctly formatted

**"Could not access microphone"**
- Check browser permissions
- Use HTTPS in production (required for microphone access)

**"Error transcribing audio"**
- Verify your Groq API key is valid
- Check your internet connection
- Ensure audio file is not corrupted

### Frontend Issues

**"Unable to connect to the server"**
- Make sure backend is running on port 8000
- Check `VITE_API_URL` in frontend `.env`
- Verify CORS settings in `backend/app/config.py`

**Audio not playing**
- Check browser console for errors
- Verify audio format is supported
- Try a different browser

## ğŸ“Š Performance

- **Speech-to-Text**: ~0.5-1 second (Groq Whisper)
- **LLM Response**: ~0.5-1 second (Groq Llama 3.1)
- **Text-to-Speech**: ~1-2 seconds (Edge TTS)
- **Total Pipeline**: ~2-4 seconds end-to-end

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## âš ï¸ Important Disclaimer

This application is a support tool and **NOT a replacement for professional mental health care**. If you or someone you know is in crisis, please contact:

- **US**: National Suicide Prevention Lifeline: 988
- **US**: Crisis Text Line: Text HOME to 741741
- **International**: [IASP Crisis Centers](https://www.iasp.info/resources/Crisis_Centres/)

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- [Groq](https://groq.com) for ultra-fast AI inference
- [Edge TTS](https://github.com/rany2/edge-tts) for free text-to-speech
- [FastAPI](https://fastapi.tiangolo.com/) for the backend framework
- [React](https://react.dev/) and [Vite](https://vitejs.dev/) for the frontend
- [Tailwind CSS](https://tailwindcss.com/) for styling

## ğŸ“§ Contact

For questions or feedback, please open an issue on GitHub.

---

**Built with â¤ï¸ for mental health awareness and support**

